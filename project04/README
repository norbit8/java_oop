yoav




=============================
=      File description     =
=============================
SimpleHashSet.java - an abstract class implementing SimpleSet. You may expand its API if you wish, keeping
                     in mind the minimal API principal.
                     You may implement methods fromSimpleSet or keep them abstract as you see fit
OpenHashSet.java - A hash-set based on chaining.
ClosedHashSet.java - A hash-set based on closed-hashing with quadratic probing.
                     Extends SimpleHashSet.
SpecialString.java - Special class representing a String with another feature
                     which is a parameter which omits true if the string should be
                     considered as deleted, false otherwise.
WrapperLinkedList.java -  Wrapper-class that has a LinkedList<String>
                          and delegates methods to it
CollectionFacadeSet.java - Facade design pattern implementation for the set collection.
                           facade provides a simplified interface to a more complex class or even a set of
                           classes.
SimpleSetPerformanceAnalyzer.java - This class measures the run-times of the data structures:
                                      * OpenHashSet.
                                      * ClosedHashSet.
                                      * TreeSet (Java's vanilla implementation).
                                      * LinkedList (Java's vanilla implementation).
                                      * HashSet (Java's vanilla implementation).
RESULTS - The file which collects all the performance analyzing results.
README - this.

=============================
=          Design           =
=============================
In this exercise we used the Design patter of Facade,
which help a lot when testing the performance of all
the required data structures,
because I could create a new array of type HashSet and add all the collections and the HashSets
which are now has a common type "HashSet" thanks to the facade implementation.


=============================
=  Implementation details   =
=============================
How I implemented OpenHashSet and ClosedHashSet:
I implemented the OpenHashSet using the class WrapperLinkedList which is a class that includes a LinkedList
of strings delegated in it, and there-for I could create an Array of this Object.
In the class WrapperLinkedList I delegated just the methods I needed to use In the Implementation of the
OpenHashSet, such as: push, pop, remove, isEmpty, and Contains.
In contrast to the OpenHashSet in the ClosedHashSet I used an array of SpecialString, which is just a String
with a state "deleted" which helps me determine whether the string is in a deleted state or is it available
in the hash-set.
Because There is common ancestor class to the OpenHashSet and ClosedHashSet I decided to Implement some of
their functions in the ancestor class (SimpleHashSet) such as: CheckFactorAdd(), and CheckFactorDelete()
both functions verify if we're not exceeding the LowerLoadFactor and the UpperLoadFactor.

How I implemented the deletion mechanism in the ClosedHashSet:
Because I created the class SpecialString the way I created it, I had a field which states if the string
is deleted or not, and a getter function to probe the state of the field.
That way every time I needed to add a new string to the hash-table I could differ between a deleted place and
a used one.

=============================
=    Answers to questions   =
=============================
Answered the questions about the Implementation of the hash-sets in the Implementation details section.
The Result of the analysis discussion:
*Account, in separate, for OpenHashSet’s and ClosedHashSet’s bad results for data1.txt
- Because data1.txt contains a list of 99,999 different words with the same hash,
  when using hash table to store them there are many collisions, and there for it will need to compute
  where to store them much harder than if they had different hash, also this is very dominant in the closed
  hash table because when the table has many elements inside and then needs to resize all the elements are
  re-hashed and because of all the collisions we unfortunately need to iterate over the list many times in
  order to find a
  valid spot.
*Summarize the strengths and weaknesses of each of the data structures as reflected by the results.
 Which would you use for which purposes?
- From the results I learn that if I want a faster insertion of values
  I usually should use TreeSet or Java's
  implementation for HashSet, LinkedList is not so good in inserting elements (O(n)).
  But If I want a faster contain method usually I should pick any HashSet or Tree set but for the cases where
  Im searching for a specific key which has the same hashed value
  of many values in my hash table it will most
  definitely be slower. LinkedLists are again bad at searching for a value.
*How did your two implementations compare between themselves?
- Generally ClosedHashSet preformed worse then the OpenHashSet, when there are many collisions the
  ClosedHashSet will fill faster and when searching for a specific value it will take much longer because
  it needs to compute the spot which the value should be in and it might not be there.
*How did your implementations compare to Java’s built in HashSet?
- I found that my implementation was much slower than Java's built-in
  HashSet in all the tests which feels bad.
  TBH but from a quick search on the internet I found that they use a second hash function which is somewhat
  like our clam method and also they use much larger initial hashTable which makes collisions much rare.
  also I read that the hash table implementation includes a random element that makes it harder for an
  attacker to predict which keys will cause collisions, which is a big plus.